{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPc+W1WXjs05srTw48nA310",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abdulsamadkhan/Tutorial/blob/main/n_gram.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Unigram, Bigram, Trigram and N-Gram\n",
        "The provided Python code is a text processing and N-gram modeling example. It takes a sample text as input and calculates unigram, bigram, and trigram models, then prints the probability distributions for each model. Here's a detailed explanation of each part of the code:\n",
        "\n",
        "1. **Importing Libraries**:\n",
        "   - `import re`: This imports the Python regular expressions library, which will be used to remove punctuation from the text.\n",
        "   - `from collections import defaultdict`: This imports the `defaultdict` data structure from the `collections` module, which will be used to create dictionaries with default values.\n",
        "\n",
        "2. **Preprocessing Function (`preprocess_text`)**:\n",
        "   - This function takes a text string as input and performs the following steps:\n",
        "     - Removes punctuation using regular expressions (`re.sub`).\n",
        "     - Converts the text to lowercase.\n",
        "     - Tokenizes the text into individual words by splitting it using spaces.\n",
        "   - The function returns a list of words.\n",
        "\n",
        "3. **Unigram Model Function (`calculate_unigram_model`)**:\n",
        "   - This function takes a list of words as input.\n",
        "   - It creates a dictionary (`unigram_model`) to store unigram (single-word) probabilities.\n",
        "   - For each word in the input, it increments the count of that word in the dictionary and normalizes it by dividing by the total number of words in the text.\n",
        "   - The function returns the unigram model, where each word is associated with its probability of occurrence.\n",
        "\n",
        "4. **Bigram Model Function (`calculate_bigram_model`)**:\n",
        "   - This function takes a list of words as input.\n",
        "   - It creates a dictionary (`bigram_model`) to store bigram (two-word) probabilities.\n",
        "   - It iterates through the list of words and creates bigrams (pairs of consecutive words).\n",
        "   - For each bigram, it increments the count of that bigram in the dictionary.\n",
        "   - After counting all bigrams, it normalizes the counts by dividing by the total number of bigrams.\n",
        "   - The function returns the bigram model, where each bigram is associated with its probability of occurrence.\n",
        "\n",
        "5. **Trigram Model Function (`calculate_trigram_model`)**:\n",
        "   - This function is similar to the bigram model function but operates on trigrams (three-word sequences) instead.\n",
        "   - It creates a dictionary (`trigram_model`) to store trigram probabilities.\n",
        "   - It iterates through the list of words and creates trigrams (triplets of consecutive words).\n",
        "   - For each trigram, it increments the count of that trigram in the dictionary.\n",
        "   - After counting all trigrams, it normalizes the counts by dividing by the total number of trigrams.\n",
        "   - The function returns the trigram model, where each trigram is associated with its probability of occurrence.\n",
        "\n",
        "6. **Sample Text**:\n",
        "   - A sample text string is defined, which contains the text you want to analyze.\n",
        "\n",
        "7. **Text Preprocessing and Model Calculation**:\n",
        "   - The sample text is preprocessed using the `preprocess_text` function to obtain a list of words.\n",
        "\n",
        "   - Unigram, bigram, and trigram models are calculated using their respective functions, and the results are stored in the `unigram_model`, `bigram_model`, and `trigram_model` dictionaries.\n",
        "\n",
        "8. **Printing the Models**:\n",
        "   - The code then prints the probability distributions for each model:\n",
        "     - For the unigram model, it prints each word and its probability.\n",
        "     - For the bigram model, it prints each bigram (pair of words) and its probability.\n",
        "     - For the trigram model, it prints each trigram (triplet of words) and its probability.\n",
        "\n",
        "The output of the code will show the probability distributions for each N-gram model, providing insights into the likelihood of different word sequences in the sample text."
      ],
      "metadata": {
        "id": "DfbbfSo4eZZ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from collections import defaultdict\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Remove punctuation and convert to lowercase\n",
        "    text = re.sub(r'[^\\w\\s]', '', text).lower()\n",
        "    # Tokenize the text into words\n",
        "    words = text.split()\n",
        "    return words\n",
        "\n",
        "def calculate_unigram_model(words):\n",
        "    unigram_model = defaultdict(int)\n",
        "    total_words = len(words)\n",
        "    for word in words:\n",
        "        unigram_model[word] += 1 / total_words\n",
        "    return unigram_model\n",
        "\n",
        "def calculate_bigram_model(words):\n",
        "    bigram_model = defaultdict(float)\n",
        "    for i in range(len(words) - 1):\n",
        "        bigram = (words[i], words[i + 1])\n",
        "        bigram_model[bigram] += 1\n",
        "    total_bigrams = len(words) - 1\n",
        "    for bigram, count in bigram_model.items():\n",
        "        bigram_model[bigram] = count / total_bigrams\n",
        "    return bigram_model\n",
        "\n",
        "def calculate_trigram_model(words):\n",
        "    trigram_model = defaultdict(float)\n",
        "    for i in range(len(words) - 2):\n",
        "        trigram = (words[i], words[i + 1], words[i + 2])\n",
        "        trigram_model[trigram] += 1\n",
        "    total_trigrams = len(words) - 2\n",
        "    for trigram, count in trigram_model.items():\n",
        "        trigram_model[trigram] = count / total_trigrams\n",
        "    return trigram_model\n",
        "\n",
        "# Sample text\n",
        "text = \"This is a simple example of a unigram, bigram, and trigram model calculation.\"\n",
        "\n",
        "# Preprocess the text\n",
        "words = preprocess_text(text)\n",
        "\n",
        "# Calculate the models\n",
        "unigram_model = calculate_unigram_model(words)\n",
        "bigram_model = calculate_bigram_model(words)\n",
        "trigram_model = calculate_trigram_model(words)\n",
        "\n",
        "# Print the models\n",
        "print(\"Unigram Model:\")\n",
        "for word, prob in unigram_model.items():\n",
        "    print(f\"{word}: {prob:.4f}\")\n",
        "\n",
        "print(\"\\nBigram Model:\")\n",
        "for bigram, prob in bigram_model.items():\n",
        "    print(f\"{bigram[0]} {bigram[1]}: {prob:.4f}\")\n",
        "\n",
        "print(\"\\nTrigram Model:\")\n",
        "for trigram, prob in trigram_model.items():\n",
        "    print(f\"{trigram[0]} {trigram[1]} {trigram[2]}: {prob:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "myXef5-5eYqb",
        "outputId": "843b7e18-0b98-4c80-d1a1-3ce38d7018b5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unigram Model:\n",
            "this: 0.0769\n",
            "is: 0.0769\n",
            "a: 0.1538\n",
            "simple: 0.0769\n",
            "example: 0.0769\n",
            "of: 0.0769\n",
            "unigram: 0.0769\n",
            "bigram: 0.0769\n",
            "and: 0.0769\n",
            "trigram: 0.0769\n",
            "model: 0.0769\n",
            "calculation: 0.0769\n",
            "\n",
            "Bigram Model:\n",
            "this is: 0.0833\n",
            "is a: 0.0833\n",
            "a simple: 0.0833\n",
            "simple example: 0.0833\n",
            "example of: 0.0833\n",
            "of a: 0.0833\n",
            "a unigram: 0.0833\n",
            "unigram bigram: 0.0833\n",
            "bigram and: 0.0833\n",
            "and trigram: 0.0833\n",
            "trigram model: 0.0833\n",
            "model calculation: 0.0833\n",
            "\n",
            "Trigram Model:\n",
            "this is a: 0.0909\n",
            "is a simple: 0.0909\n",
            "a simple example: 0.0909\n",
            "simple example of: 0.0909\n",
            "example of a: 0.0909\n",
            "of a unigram: 0.0909\n",
            "a unigram bigram: 0.0909\n",
            "unigram bigram and: 0.0909\n",
            "bigram and trigram: 0.0909\n",
            "and trigram model: 0.0909\n",
            "trigram model calculation: 0.0909\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jdwFWxK6eWGR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GzXskZL0eXUF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}